{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoulikaGudipally/Moulika_INFO5731_Fall2023/blob/main/Gudipally_Moulika_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Two**\n",
        "\n",
        "In this assignment, you will try to gather text data from open data source via web scraping or API. After that you need to clean the text data and syntactic analysis of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(40 points). Write a python program to collect text data from **either of the following sources** and save the data into a **csv file**:\n",
        "\n",
        "(1) Collect all the customer reviews of a product (you can choose any porduct) on amazon.\n",
        "\n",
        "(2) Collect the top 10000 User Reviews of a film recently in 2023 or 2022 (you can choose any film) from IMDB.\n",
        "\n",
        "(3) Collect all the reviews of the top 1000 most popular software from [G2](https://www.g2.com/) or [Capterra](https://www.capterra.com/)\n",
        "\n",
        "(4) Collect the abstracts of the top 10000 research papers by using the query \"machine learning\", \"data science\", \"artifical intelligence\", or \"information extraction\" from [Semantic Scholar](https://www.semanticscholar.org).\n",
        "\n",
        "(5) Collect all the information of the 904 narrators in the [Densho Digital Repository](https://ddr.densho.org/narrators/).\n",
        "\n",
        "(6) Collect the top 10000 reddits by using a hashtag (you can use any hashtag) from Reddits.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PuFPKhC0m1fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee31ec00-3307-44a2-f2c2-f466f905d08b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 25 reviews to imdb_reviews.csv\n"
          ]
        }
      ],
      "source": [
        "#question 2\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# URL of the movie's reviews on IMDB\n",
        "url = 'https://www.imdb.com/title/tt0111161/reviews?ref_=tt_ql_3'\n",
        "\n",
        "# Send an HTTP GET request to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find and extract review elements\n",
        "    review_elements = soup.find_all('div', class_='text show-more__control')\n",
        "\n",
        "    # Create a list to store the reviews\n",
        "    reviews = []\n",
        "\n",
        "    for review in review_elements:\n",
        "        reviews.append(review.get_text().strip())\n",
        "\n",
        "    # Create a DataFrame from the collected data\n",
        "    df = pd.DataFrame({'Review': reviews})\n",
        "\n",
        "    # Save the data to a CSV file\n",
        "    df.to_csv('imdb_reviews.csv', index=False)\n",
        "    print(f'Saved {len(reviews)} reviews to imdb_reviews.csv')\n",
        "\n",
        "else:\n",
        "    print('Failed to fetch data from IMDB')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "gN9LK8Y_ivdW",
        "outputId": "fce1a3ba-0029-43a5-cc41-e8fe6d0b3d39"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Review\n",
              "0  The Shawshank Redemption is written and direct...\n",
              "1  It is no wonder that the film has such a high ...\n",
              "2  I'm trying to save you money; this is the last...\n",
              "3  This movie is not your ordinary Hollywood flic...\n",
              "4  In its Oscar year, Shawshank Redemption (writt...\n",
              "5  The best movie in history and the best ending ...\n",
              "6  Shawshank Redemption is without doubt one of t...\n",
              "7  One of the finest films made in recent years. ...\n",
              "8  Misery and Stand By Me were the best adaptatio...\n",
              "9  I've lost count of the number of times I have ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83da2c85-3e27-4ba3-9872-4e4adf4e13d5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Shawshank Redemption is written and direct...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It is no wonder that the film has such a high ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'm trying to save you money; this is the last...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This movie is not your ordinary Hollywood flic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In its Oscar year, Shawshank Redemption (writt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The best movie in history and the best ending ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Shawshank Redemption is without doubt one of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>One of the finest films made in recent years. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Misery and Stand By Me were the best adaptatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I've lost count of the number of times I have ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83da2c85-3e27-4ba3-9872-4e4adf4e13d5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-83da2c85-3e27-4ba3-9872-4e4adf4e13d5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-83da2c85-3e27-4ba3-9872-4e4adf4e13d5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-323e141c-341e-41e6-ae6a-5a4c712c911d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-323e141c-341e-41e6-ae6a-5a4c712c911d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-323e141c-341e-41e6-ae6a-5a4c712c911d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Write a python program to **clean the text data** you collected above and save the data in a new column in the csv file. The data cleaning steps include:\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the [stopwords list](https://gist.github.com/sebleier/554280).\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming.\n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vATjQNTY8buA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f334ff4c-2979-43ef-db8f-71b28b910daa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved cleaned data to imdb_reviews_cleaned.csv\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download stopwords data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('imdb_reviews.csv')\n",
        "\n",
        "# Initialize stopwords, stemmer, and lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Function to clean and preprocess the text\n",
        "def clean_text(text):\n",
        "    # Remove special characters and punctuation\n",
        "    text = ''.join([char for char in text if char not in string.punctuation])\n",
        "\n",
        "    # Remove numbers\n",
        "    text = ''.join([char for char in text if not char.isdigit()])\n",
        "\n",
        "    # Tokenize the text (split it into words)\n",
        "    words = text.split()\n",
        "\n",
        "    # Remove stopwords and lowercase the words\n",
        "    words = [word.lower() for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    # Stemming and lemmatization\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply the cleaning function to the 'Review' column and store the result in a new column 'Cleaned_Review'\n",
        "df['Cleaned_Review'] = df['Review'].apply(clean_text)\n",
        "\n",
        "# Save the cleaned data to the CSV file\n",
        "df.to_csv('imdb_reviews_cleaned.csv', index=False)\n",
        "\n",
        "print(f'Saved cleaned data to imdb_reviews_cleaned.csv')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(30 points). Write a python program to conduct **syntax and structure analysis** of the clean text you just saved above. The syntax and structure analysis includes:\n",
        "\n",
        "(1) Parts of Speech (POS) Tagging: Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) Constituency Parsing and Dependency Parsing: print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) Named Entity Recognition: Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QQKnPjPDHJHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b51036-728d-487d-84c4-033c87de4358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Sentence: shawshank redempt written direct frank darabont adapt stephen king novella rita hayworth shawshank redempt star tim robbin morgan freeman film portray stori andi dufresn robbin banker sentenc two life sentenc shawshank state prison appar murder wife lover andi find tough go find solac friendship form fellow inmat elli red red freeman thing start pick warden find andi prison job befit talent banker howev arriv anoth inmat go vastli chang thing themther fanfar bunt put releas film back titl didnt give much inkl anyon columbia pictur unsur market shawshank redempt bare regist box offic howev come academi award time film receiv sever nomin although none stir interest film home entertain releas rest say histori film final found audienc saw film propel almost mythic proport endear modern day classic someth delight fan whilst simultan baffl detractor one thing sure though ever side shawshank fenc sit film continu gather new fan simpli never go away loo mythic statusit possibl simplic send hater film cinemat spasm implaus plot appar sentiment edg make nonsens prison life two chief complaint dislik film passion yet charact richli drawn movingli perform strike churlish human drama that deal hope friendship faith sentiment aspect inde act counterpoint suffer degrad shatter soul involv protagonist cosi prison life say chanc need human connect never need incarcer sure given quit terrif perform robbin never better freeman sublim make easi easiest thing world warm andi redthos support arent fare bad either bob gunton coil spring smarm warden norton jame whitmor heart achingli great birdman shawshank clanci brown menac antagonist capt byron hadley william sadler amus heywood mark rolston impress vile bog diamond there roger deakin lush cinematographi camera grace glide prison offer almost ether hope charact ye music ping conjunct emot flow movi thoma newman score mostli piano base dovetail neatli andi state mind excel select soundtrack rang like hank william gorgeou le nozz di figaro mozartif love shawshank love last lifetim everi view bring array emot anger revil happi sad inspir warmth reduc harden misti eye wonder el though shawshank offer hope charact movi better life better world u\n",
            "\n",
            "Dependency Parsing Tree:\n",
            "shawshank (compound --> redempt)\n",
            "redempt (nsubj --> written)\n",
            "written (ROOT --> written)\n",
            "direct (amod --> darabont)\n",
            "frank (amod --> darabont)\n",
            "darabont (compound --> adapt)\n",
            "adapt (ccomp --> written)\n",
            "stephen (compound --> novella)\n",
            "king (compound --> novella)\n",
            "novella (compound --> star)\n",
            "rita (compound --> star)\n",
            "hayworth (compound --> redempt)\n",
            "shawshank (compound --> redempt)\n",
            "redempt (compound --> star)\n",
            "star (compound --> robbin)\n",
            "tim (compound --> robbin)\n",
            "robbin (compound --> stori)\n",
            "morgan (compound --> stori)\n",
            "freeman (compound --> stori)\n",
            "film (compound --> stori)\n",
            "portray (compound --> stori)\n",
            "stori (nsubj --> andi)\n",
            "andi (ccomp --> adapt)\n",
            "dufresn (compound --> sentenc)\n",
            "robbin (compound --> banker)\n",
            "banker (compound --> sentenc)\n",
            "sentenc (dative --> andi)\n",
            "two (nummod --> sentenc)\n",
            "life (compound --> sentenc)\n",
            "sentenc (compound --> andi)\n",
            "shawshank (compound --> appar)\n",
            "state (compound --> appar)\n",
            "prison (compound --> appar)\n",
            "appar (compound --> wife)\n",
            "murder (compound --> wife)\n",
            "wife (compound --> lover)\n",
            "lover (compound --> andi)\n",
            "andi (nsubj --> find)\n",
            "find (conj --> written)\n",
            "tough (amod --> go)\n",
            "go (nsubj --> find)\n",
            "find (ccomp --> find)\n",
            "solac (compound --> form)\n",
            "friendship (compound --> form)\n",
            "form (nmod --> thing)\n",
            "fellow (compound --> inmat)\n",
            "inmat (compound --> thing)\n",
            "elli (nmod --> thing)\n",
            "red (amod --> freeman)\n",
            "red (compound --> freeman)\n",
            "freeman (compound --> thing)\n",
            "thing (nsubj --> start)\n",
            "start (ccomp --> find)\n",
            "pick (compound --> find)\n",
            "warden (compound --> find)\n",
            "find (compound --> inmat)\n",
            "andi (compound --> inmat)\n",
            "prison (compound --> inmat)\n",
            "job (compound --> inmat)\n",
            "befit (compound --> talent)\n",
            "talent (compound --> banker)\n",
            "banker (compound --> howev)\n",
            "howev (compound --> inmat)\n",
            "arriv (compound --> inmat)\n",
            "anoth (compound --> inmat)\n",
            "inmat (nsubj --> go)\n",
            "go (ccomp --> find)\n",
            "vastli (compound --> thing)\n",
            "chang (compound --> thing)\n",
            "thing (dobj --> go)\n",
            "themther (nmod --> film)\n",
            "fanfar (advmod --> bunt)\n",
            "bunt (amod --> film)\n",
            "put (amod --> film)\n",
            "releas (compound --> film)\n",
            "film (compound --> titl)\n",
            "back (compound --> titl)\n",
            "titl (nsubj --> give)\n",
            "did (aux --> give)\n",
            "nt (neg --> give)\n",
            "give (advcl --> go)\n",
            "much (amod --> market)\n",
            "inkl (compound --> anyon)\n",
            "anyon (compound --> market)\n",
            "columbia (compound --> unsur)\n",
            "pictur (compound --> unsur)\n",
            "unsur (compound --> market)\n",
            "market (compound --> redempt)\n",
            "shawshank (compound --> redempt)\n",
            "redempt (nmod --> howev)\n",
            "bare (amod --> howev)\n",
            "regist (compound --> box)\n",
            "box (compound --> howev)\n",
            "offic (compound --> howev)\n",
            "howev (nsubj --> come)\n",
            "come (compound --> nomin)\n",
            "academi (compound --> award)\n",
            "award (compound --> time)\n",
            "time (compound --> nomin)\n",
            "film (compound --> nomin)\n",
            "receiv (compound --> sever)\n",
            "sever (compound --> nomin)\n",
            "nomin (dobj --> give)\n",
            "although (mark --> stir)\n",
            "none (nsubj --> stir)\n",
            "stir (advcl --> give)\n",
            "interest (compound --> film)\n",
            "film (compound --> rest)\n",
            "home (compound --> entertain)\n",
            "entertain (compound --> releas)\n",
            "releas (compound --> rest)\n",
            "rest (nsubj --> say)\n",
            "say (conj --> written)\n",
            "histori (compound --> film)\n",
            "film (nmod --> audienc)\n",
            "final (amod --> audienc)\n",
            "found (amod --> audienc)\n",
            "audienc (nsubj --> saw)\n",
            "saw (ccomp --> say)\n",
            "film (compound --> propel)\n",
            "propel (ccomp --> saw)\n",
            "almost (advmod --> mythic)\n",
            "mythic (amod --> proport)\n",
            "proport (nmod --> endear)\n",
            "endear (nmod --> fan)\n",
            "modern (amod --> day)\n",
            "day (nmod --> fan)\n",
            "classic (amod --> fan)\n",
            "someth (amod --> fan)\n",
            "delight (compound --> fan)\n",
            "fan (dobj --> propel)\n",
            "whilst (prep --> saw)\n",
            "simultan (compound --> detractor)\n",
            "baffl (compound --> detractor)\n",
            "detractor (pobj --> whilst)\n",
            "one (nummod --> thing)\n",
            "thing (dobj --> saw)\n",
            "sure (amod --> thing)\n",
            "though (mark --> side)\n",
            "ever (advmod --> side)\n",
            "side (advcl --> saw)\n",
            "shawshank (compound --> fenc)\n",
            "fenc (nmod --> continu)\n",
            "sit (compound --> continu)\n",
            "film (compound --> continu)\n",
            "continu (nsubj --> gather)\n",
            "gather (ccomp --> saw)\n",
            "new (amod --> simpli)\n",
            "fan (compound --> simpli)\n",
            "simpli (nsubj --> go)\n",
            "never (neg --> go)\n",
            "go (ccomp --> gather)\n",
            "away (advmod --> go)\n",
            "loo (amod --> simplic)\n",
            "mythic (amod --> simplic)\n",
            "statusit (compound --> possibl)\n",
            "possibl (compound --> simplic)\n",
            "simplic (nsubj --> send)\n",
            "send (advcl --> go)\n",
            "hater (compound --> spasm)\n",
            "film (compound --> spasm)\n",
            "cinemat (compound --> spasm)\n",
            "spasm (compound --> edg)\n",
            "implaus (compound --> edg)\n",
            "plot (compound --> appar)\n",
            "appar (compound --> sentiment)\n",
            "sentiment (compound --> edg)\n",
            "edg (nsubj --> make)\n",
            "make (ccomp --> send)\n",
            "nonsens (compound --> life)\n",
            "prison (compound --> life)\n",
            "life (nsubj --> dislik)\n",
            "two (nummod --> complaint)\n",
            "chief (amod --> complaint)\n",
            "complaint (compound --> dislik)\n",
            "dislik (compound --> passion)\n",
            "film (compound --> passion)\n",
            "passion (dobj --> make)\n",
            "yet (cc --> make)\n",
            "charact (conj --> saw)\n",
            "richli (npadvmod --> drawn)\n",
            "drawn (amod --> movingli)\n",
            "movingli (nsubj --> perform)\n",
            "perform (ccomp --> charact)\n",
            "strike (compound --> churlish)\n",
            "churlish (amod --> drama)\n",
            "human (amod --> drama)\n",
            "drama (dobj --> perform)\n",
            "that (nsubj --> deal)\n",
            "deal (relcl --> drama)\n",
            "hope (compound --> counterpoint)\n",
            "friendship (compound --> sentiment)\n",
            "faith (compound --> sentiment)\n",
            "sentiment (compound --> counterpoint)\n",
            "aspect (compound --> inde)\n",
            "inde (compound --> counterpoint)\n",
            "act (compound --> counterpoint)\n",
            "counterpoint (dobj --> deal)\n",
            "suffer (compound --> soul)\n",
            "degrad (compound --> shatter)\n",
            "shatter (compound --> soul)\n",
            "soul (nsubj --> involv)\n",
            "involv (conj --> saw)\n",
            "protagonist (amod --> cosi)\n",
            "cosi (compound --> life)\n",
            "prison (compound --> life)\n",
            "life (dobj --> involv)\n",
            "say (ccomp --> say)\n",
            "chanc (nsubj --> need)\n",
            "need (ccomp --> say)\n",
            "human (amod --> connect)\n",
            "connect (nsubj --> need)\n",
            "never (neg --> need)\n",
            "need (ccomp --> need)\n",
            "incarcer (dobj --> need)\n",
            "sure (advmod --> need)\n",
            "given (prep --> written)\n",
            "quit (xcomp --> given)\n",
            "terrif (compound --> robbin)\n",
            "perform (compound --> robbin)\n",
            "robbin (dobj --> quit)\n",
            "never (neg --> better)\n",
            "better (amod --> sublim)\n",
            "freeman (amod --> sublim)\n",
            "sublim (nsubj --> make)\n",
            "make (conj --> written)\n",
            "easi (amod --> thing)\n",
            "easiest (amod --> thing)\n",
            "thing (nmod --> support)\n",
            "world (nmod --> andi)\n",
            "warm (amod --> andi)\n",
            "andi (appos --> thing)\n",
            "redthos (compound --> support)\n",
            "support (nsubj --> are)\n",
            "are (ccomp --> make)\n",
            "nt (neg --> are)\n",
            "fare (advmod --> bad)\n",
            "bad (acomp --> are)\n",
            "either (preconj --> achingli)\n",
            "bob (compound --> smarm)\n",
            "gunton (compound --> coil)\n",
            "coil (compound --> smarm)\n",
            "spring (compound --> smarm)\n",
            "smarm (compound --> heart)\n",
            "warden (compound --> norton)\n",
            "norton (compound --> heart)\n",
            "jame (compound --> whitmor)\n",
            "whitmor (compound --> heart)\n",
            "heart (compound --> achingli)\n",
            "achingli (compound --> birdman)\n",
            "great (amod --> birdman)\n",
            "birdman (compound --> diamond)\n",
            "shawshank (compound --> antagonist)\n",
            "clanci (compound --> brown)\n",
            "brown (compound --> antagonist)\n",
            "menac (compound --> antagonist)\n",
            "antagonist (compound --> sadler)\n",
            "capt (compound --> byron)\n",
            "byron (compound --> sadler)\n",
            "hadley (compound --> sadler)\n",
            "william (compound --> sadler)\n",
            "sadler (compound --> mark)\n",
            "amus (compound --> mark)\n",
            "heywood (compound --> mark)\n",
            "mark (compound --> rolston)\n",
            "rolston (nsubj --> impress)\n",
            "impress (nmod --> diamond)\n",
            "vile (amod --> diamond)\n",
            "bog (compound --> diamond)\n",
            "diamond (nsubj --> offer)\n",
            "there (advmod --> diamond)\n",
            "roger (compound --> prison)\n",
            "deakin (nmod --> prison)\n",
            "lush (compound --> grace)\n",
            "cinematographi (amod --> grace)\n",
            "camera (compound --> grace)\n",
            "grace (compound --> prison)\n",
            "glide (compound --> prison)\n",
            "prison (nsubj --> offer)\n",
            "offer (nsubj --> charact)\n",
            "almost (advmod --> ether)\n",
            "ether (amod --> hope)\n",
            "hope (dobj --> offer)\n",
            "charact (conj --> make)\n",
            "ye (amod --> ping)\n",
            "music (compound --> ping)\n",
            "ping (nmod --> newman)\n",
            "conjunct (amod --> movi)\n",
            "emot (compound --> movi)\n",
            "flow (compound --> movi)\n",
            "movi (compound --> newman)\n",
            "thoma (compound --> newman)\n",
            "newman (nsubj --> score)\n",
            "score (ccomp --> charact)\n",
            "mostli (compound --> dovetail)\n",
            "piano (compound --> base)\n",
            "base (compound --> dovetail)\n",
            "dovetail (compound --> neatli)\n",
            "neatli (nsubj --> andi)\n",
            "andi (compound --> mind)\n",
            "state (compound --> mind)\n",
            "mind (nsubj --> excel)\n",
            "excel (conj --> make)\n",
            "select (amod --> rang)\n",
            "soundtrack (compound --> rang)\n",
            "rang (nsubj --> bring)\n",
            "like (prep --> rang)\n",
            "hank (compound --> love)\n",
            "william (compound --> love)\n",
            "gorgeou (nmod --> love)\n",
            "le (nmod --> figaro)\n",
            "nozz (nmod --> figaro)\n",
            "di (compound --> figaro)\n",
            "figaro (compound --> love)\n",
            "mozartif (compound --> love)\n",
            "love (compound --> love)\n",
            "shawshank (compound --> love)\n",
            "love (pobj --> like)\n",
            "last (amod --> lifetim)\n",
            "lifetim (nmod --> view)\n",
            "everi (amod --> view)\n",
            "view (nsubj --> bring)\n",
            "bring (ccomp --> excel)\n",
            "array (compound --> emot)\n",
            "emot (nmod --> happi)\n",
            "anger (nmod --> happi)\n",
            "revil (amod --> happi)\n",
            "happi (dobj --> bring)\n",
            "sad (compound --> inspir)\n",
            "inspir (compound --> warmth)\n",
            "warmth (appos --> happi)\n",
            "reduc (compound --> harden)\n",
            "harden (compound --> misti)\n",
            "misti (compound --> eye)\n",
            "eye (compound --> wonder)\n",
            "wonder (compound --> el)\n",
            "el (dobj --> bring)\n",
            "though (mark --> offer)\n",
            "shawshank (compound --> offer)\n",
            "offer (advcl --> bring)\n",
            "hope (compound --> charact)\n",
            "charact (compound --> movi)\n",
            "movi (dobj --> offer)\n",
            "better (amod --> life)\n",
            "life (dobj --> offer)\n",
            "better (amod --> u)\n",
            "world (compound --> u)\n",
            "u (dobj --> bring)\n",
            "Entities of type 'GPE':\n",
            "darabont: 9\n",
            "anyon columbia: 1\n",
            "ohio: 1\n",
            "washington: 1\n",
            "measur: 1\n",
            "prais: 1\n",
            "believ: 1\n",
            "harden crimin: 1\n",
            "Entities of type 'PERSON':\n",
            "rita hayworth: 4\n",
            "tim robbin morgan freeman: 3\n",
            "andi dufresn robbin banker: 1\n",
            "appar murder: 1\n",
            "lover andi: 1\n",
            "red freeman: 1\n",
            "howev arriv: 1\n",
            "chang: 1\n",
            "clanci brown: 1\n",
            "hadley william sadler: 1\n",
            "roger deakin: 1\n",
            "mostli piano: 1\n",
            "neatli andi: 1\n",
            "hank william gorgeou: 1\n",
            "andi dufresn: 7\n",
            "frame everi: 1\n",
            "tim robbin: 6\n",
            "elli boyd: 3\n",
            "freeman freeman: 1\n",
            "robbin: 1\n",
            "mani firstli titl clunker icon: 1\n",
            "dvd tim robbin: 1\n",
            "everi opportun: 1\n",
            "narr: 1\n",
            "everi shot tower: 1\n",
            "andi robbin: 1\n",
            "zihuatanejo: 1\n",
            "mani: 1\n",
            "figur: 1\n",
            "bob gunton: 2\n",
            "nixon: 1\n",
            "tom hank forrest gump freeman: 1\n",
            "freeman: 7\n",
            "mozart aria: 1\n",
            "beauti profound: 1\n",
            "cri brook death: 1\n",
            "freeman robbin majest perform learn: 1\n",
            "stephen king: 6\n",
            "miseri: 2\n",
            "shine brilliantli: 1\n",
            "tim robbin sent: 1\n",
            "freeman tim robbin: 1\n",
            "everi time: 3\n",
            "deserv prais: 1\n",
            "tim robbin show: 1\n",
            "clanci brown william sadler brian: 1\n",
            "includ titl: 1\n",
            "everi: 1\n",
            "brook hatlen: 1\n",
            "paul newman: 1\n",
            "andi dufresn tim robbin: 2\n",
            "disciplin: 1\n",
            "jaw hang: 1\n",
            "everi moment: 1\n",
            "scarytim robbin: 1\n",
            "andi dufran wrongli: 1\n",
            "billi alli mcbeal tommi: 1\n",
            "luke: 1\n",
            "tim robbin banker: 1\n",
            "luke bob stroud: 1\n",
            "morgan freeman: 1\n",
            "film robert redford brubak: 1\n",
            "bizarr: 1\n",
            "capac acut develop: 1\n",
            "lover: 1\n",
            "elli commonli refer: 1\n",
            "andi demeanor: 1\n",
            "cun thoma newman: 1\n",
            "legendari hollywood: 1\n",
            "newman: 1\n",
            "hatlen brook: 1\n",
            "dedic art: 1\n",
            "motiv creat: 1\n",
            "appar: 1\n",
            "freeman terrif togeth: 1\n",
            "clanci brown bob gunton: 1\n",
            "pasto colombiavia l: 1\n",
            "everi area: 1\n",
            "activ: 1\n",
            "precis voter: 1\n",
            "invit: 1\n",
            "nightmar: 1\n",
            "red mainman: 1\n",
            "piqu theatric: 1\n",
            "avid moviego: 1\n",
            "filmtim robbin star: 1\n",
            "dufresn bob gunton: 1\n",
            "samuel norton: 1\n",
            ": 1\n",
            "andi dufresn struggl: 1\n",
            "circumst howev realli movi: 1\n",
            "Entities of type 'CARDINAL':\n",
            "two: 13\n",
            "five: 1\n",
            "one: 21\n",
            "seven: 4\n",
            "zero: 1\n",
            "three: 1\n",
            "ten: 1\n",
            "almost two: 1\n",
            "half: 1\n",
            "eight: 1\n",
            "someth: 1\n",
            "million: 2\n",
            "Entities of type 'ORG':\n",
            "solac: 2\n",
            "simultan baffl detractor one: 1\n",
            "freeman: 1\n",
            "nozz: 1\n",
            "premis movi make: 1\n",
            "messag movi: 1\n",
            "mola: 1\n",
            "forget movi: 1\n",
            "solac eventu redempt act: 1\n",
            "believ despit: 1\n",
            "morgan freeman: 3\n",
            "genr: 2\n",
            "whenev talk movi friend: 1\n",
            "movi friend: 1\n",
            "inspir believ one: 1\n",
            "movi sway: 1\n",
            "wallsin tradit cool: 1\n",
            "newman: 2\n",
            "believ manor: 1\n",
            "narrat: 1\n",
            "red red morgan freeman imprison mani: 1\n",
            "morgan freeman charact red anyth predestin: 1\n",
            "weekenda starkli paltri: 1\n",
            "inmi initi: 1\n",
            "mexico central america usa: 1\n",
            "morgan freeman elli boyd: 1\n",
            "believ one: 1\n",
            "Entities of type 'DATE':\n",
            "spring: 1\n",
            "today: 2\n",
            "oscar year: 1\n",
            "everyon day day: 1\n",
            "year: 9\n",
            "recent year: 1\n",
            "talk year: 1\n",
            "age day: 1\n",
            "year ago: 1\n",
            "summer: 1\n",
            "past year: 2\n",
            "one day: 1\n",
            "year earlier: 1\n",
            "Entities of type 'NORP':\n",
            "cri: 1\n",
            "experi: 2\n",
            "american: 1\n",
            "gorgeou: 1\n",
            "sean: 1\n",
            "seri: 1\n",
            "undeni: 2\n",
            "manageri: 1\n",
            "english: 1\n",
            "everi: 1\n",
            "Entities of type 'ORDINAL':\n",
            "second: 3\n",
            "first: 11\n",
            "Entities of type 'TIME':\n",
            "tonight: 2\n",
            "two hour: 1\n",
            "Entities of type 'FAC':\n",
            "alcatraz: 1\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load the cleaned text from the CSV file\n",
        "df = pd.read_csv('imdb_reviews_cleaned.csv')\n",
        "\n",
        "# Process the cleaned text using spaCy\n",
        "cleaned_text = df['Cleaned_Review']\n",
        "\n",
        "# (2) Dependency Parsing\n",
        "sample_sentence = cleaned_text.iloc[0]  # Using the first sentence as an example\n",
        "sample_doc = nlp(sample_sentence)\n",
        "\n",
        "print(f\"Sample Sentence: {sample_sentence}\\n\")\n",
        "\n",
        "print(\"Dependency Parsing Tree:\")\n",
        "for token in sample_doc:\n",
        "    print(f\"{token.text} ({token.dep_} --> {token.head.text})\")\n",
        "\n",
        "# (3) Named Entity Recognition\n",
        "entity_counts = {}\n",
        "\n",
        "for text in cleaned_text:\n",
        "    doc = nlp(text)\n",
        "    for ent in doc.ents:\n",
        "        entity_type = ent.label_\n",
        "        entity_text = ent.text\n",
        "        if entity_type not in entity_counts:\n",
        "            entity_counts[entity_type] = {}\n",
        "        if entity_text not in entity_counts[entity_type]:\n",
        "            entity_counts[entity_type][entity_text] = 0\n",
        "        entity_counts[entity_type][entity_text] += 1\n",
        "\n",
        "# Print entity counts\n",
        "for entity_type, entities in entity_counts.items():\n",
        "    print(f\"Entities of type '{entity_type}':\")\n",
        "    for entity, count in entities.items():\n",
        "        print(f\"{entity}: {count}\")\n",
        "\n",
        "# Example explanation for dependency parsing:\n",
        "# Dependency Parsing Tree:\n",
        "# shawshank (amod --> redempt)\n",
        "# redempt (nsubj --> written)\n",
        "# written (amod --> darabont)\n",
        "# ...\n",
        "\n",
        "# This program will analyze the entire dataset and provide dependency parsing and named entity recognition.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWOtvT2rHNWy"
      },
      "source": [
        "**Write your explanations of the constituency parsing tree and dependency parsing tree here (Question 3-2):**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constituency parsing and dependency parsing are two different approaches to analyzing the structure of a sentence in natural language processing.\n",
        "\n",
        "1. **Constituency Parsing Tree:**\n",
        "\n",
        "   Constituency parsing, often referred to as phrase structure parsing, is a method that aims to find the grammatical structure of a sentence by breaking it down into smaller constituents. These constituents can be phrases or words that are grouped together based on their syntactic roles. The result is represented as a tree structure.\n",
        "\n",
        "   In a constituency parsing tree:\n",
        "   - Each word is represented as a leaf node.\n",
        "   - Phrases, such as noun phrases (NP) and verb phrases (VP), are represented as non-terminal nodes.\n",
        "   - The root node represents the entire sentence, and it is usually labeled as 'S' (for sentence).\n",
        "   - The edges (arcs) in the tree represent the syntactic relationships between words and phrases.\n",
        "\n",
        "\n",
        "2. **Dependency Parsing Tree:**\n",
        "\n",
        "   Dependency parsing focuses on identifying the relationships between words in a sentence by assigning a directed link (dependency) between words. In a dependency parsing tree:\n",
        "   - Each word is a node in the tree.\n",
        "   - The arrows between words represent grammatical relationships, with one word serving as the head and the other as the dependent.\n",
        "   - The root of the tree represents the main verb of the sentence, and all other words in the sentence have dependencies on the root or other words.\n",
        "\n",
        "   \n",
        "Both constituency parsing and dependency parsing provide valuable insights into the grammatical structure of a sentence, and each has its own advantages and use cases in natural language processing tasks. Constituency parsing is well-suited for understanding phrases and hierarchical structure, while dependency parsing is useful for capturing syntactic dependencies between words."
      ],
      "metadata": {
        "id": "sm7Sv2xPlEqs"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
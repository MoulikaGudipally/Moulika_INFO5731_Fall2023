{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoulikaGudipally/Moulika_INFO5731_Fall2023/blob/main/Gudipally_exercise_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaJbXIvS6i7N"
      },
      "source": [
        "# **The fourth in-class-exercise (40 points in total, 03/28/2022)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ_FxFGc6i7Q"
      },
      "source": [
        "Question description: Please use the text corpus you collected in your last in-class-exercise for this exercise. Perform the following tasks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLlHXV_Y6i7R"
      },
      "source": [
        "## (1) (10 points) Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4c-qW12w6i7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341285ba-bbc9-41ba-89e1-affdf467a472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1: 0.240*\"text\" + 0.129*\"sample\" + 0.129*\"tokenized\" + 0.129*\"document\" + 0.129*\"cleaned\" + 0.019*\"with\" + 0.019*\"required\" + 0.019*\"data\" + 0.019*\"your\" + 0.019*\"list\"\n",
            "Topic 2: 0.194*\"stopwords\" + 0.194*\"remove\" + 0.194*\"punctuation\" + 0.028*\"document\" + 0.028*\"your\" + 0.028*\"text\" + 0.028*\"with\" + 0.028*\"each\" + 0.028*\"replace\" + 0.028*\"tokenized\"\n",
            "Topic 3: 0.194*\"document\" + 0.194*\"each\" + 0.194*\"list\" + 0.028*\"required\" + 0.028*\"your\" + 0.028*\"cleaned\" + 0.028*\"text\" + 0.028*\"data\" + 0.028*\"punctuation\" + 0.028*\"stemming\"\n",
            "Topic 4: 0.123*\"replace\" + 0.123*\"data\" + 0.123*\"this\" + 0.123*\"with\" + 0.123*\"your\" + 0.076*\"required\" + 0.067*\"lemmatization\" + 0.063*\"stemming\" + 0.018*\"document\" + 0.018*\"text\"\n",
            "Topic 5: 0.137*\"with\" + 0.137*\"replace\" + 0.137*\"data\" + 0.136*\"your\" + 0.086*\"stemming\" + 0.081*\"lemmatization\" + 0.071*\"required\" + 0.020*\"document\" + 0.020*\"text\" + 0.020*\"cleaned\"\n",
            "Topic 6: 0.056*\"document\" + 0.056*\"your\" + 0.056*\"required\" + 0.056*\"with\" + 0.056*\"text\" + 0.056*\"list\" + 0.056*\"punctuation\" + 0.056*\"data\" + 0.056*\"replace\" + 0.056*\"lemmatization\"\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import CoherenceModel\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "\n",
        "# Create a Dictionary and a DTM or TF-IDF matrix\n",
        "# Example of preprocessed text data\n",
        "document1 = [\"sample\", \"text\", \"document\"]\n",
        "document2 = [\"replace\", \"this\", \"with\", \"your\", \"data\"]\n",
        "document3 = [\"cleaned\", \"tokenized\", \"text\"]\n",
        "document4 = [\"remove\", \"stopwords\", \"punctuation\"]\n",
        "document5 = [\"each\", \"document\", \"list\"]\n",
        "document6 = [\"replace\", \"with\", \"your\", \"data\"]\n",
        "document7 = [\"lemmatization\", \"stemming\", \"required\"]\n",
        "\n",
        "# Create a corpus as a list of documents\n",
        "your_corpus = [document1, document2, document3, document4, document5, document6, document7]\n",
        "\n",
        "dictionary = Dictionary(your_corpus)\n",
        "corpus = [dictionary.doc2bow(doc) for doc in your_corpus]\n",
        "\n",
        "# Initialize variables\n",
        "coherence_scores = []\n",
        "k_values = range(2, 21)\n",
        "\n",
        "# Calculate coherence scores for different K values\n",
        "for k in k_values:\n",
        "    lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=k)\n",
        "    coherence_model = CoherenceModel(model=lda_model, texts=your_corpus, dictionary=dictionary, coherence='c_v')\n",
        "    coherence_scores.append(coherence_model.get_coherence())\n",
        "\n",
        "# Find the optimal K with the highest coherence score\n",
        "optimal_k = k_values[coherence_scores.index(max(coherence_scores))]\n",
        "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=optimal_k)\n",
        "topics = lda_model.show_topics(num_topics=optimal_k, num_words=10)\n",
        "\n",
        "for topic in topics:\n",
        "    print(f\"Topic {topic[0] + 1}: {topic[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj8ZYSyA6i7T"
      },
      "source": [
        "## (2) (10 points) Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DQ5A-QWP6i7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9612a9-91ba-4b95-9a60-fd70ccc1353d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.483*\"with\" + 0.483*\"your\" + 0.483*\"replace\" + 0.483*\"data\" + 0.257*\"this\" + -0.000*\"list\" + -0.000*\"each\" + -0.000*\"document\" + -0.000*\"tokenized\" + -0.000*\"cleaned\"')\n",
            "(1, '0.575*\"text\" + 0.575*\"document\" + 0.337*\"sample\" + 0.238*\"tokenized\" + 0.238*\"cleaned\" + 0.238*\"each\" + 0.238*\"list\" + 0.000*\"replace\" + -0.000*\"stemming\" + 0.000*\"with\"')\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "\n",
        "from gensim.models import LsiModel\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "# Create a Dictionary and a TDM or TF-IDF matrix\n",
        "dictionary = Dictionary(your_corpus)\n",
        "corpus = [dictionary.doc2bow(doc) for doc in your_corpus]\n",
        "\n",
        "# Initialize variables\n",
        "coherence_scores = []\n",
        "k_values = range(2, 21)\n",
        "\n",
        "# Calculate coherence scores for different K values\n",
        "for k in k_values:\n",
        "    lsa_model = LsiModel(corpus=corpus, id2word=dictionary, num_topics=k)\n",
        "    coherence_model = CoherenceModel(model=lsa_model, texts=your_corpus, dictionary=dictionary, coherence='c_v')\n",
        "    coherence_scores.append(coherence_model.get_coherence())\n",
        "\n",
        "# Find the optimal K with the highest coherence score\n",
        "optimal_k = k_values[coherence_scores.index(max(coherence_scores))]\n",
        "lsa_model = LsiModel(corpus=corpus, id2word=dictionary, num_topics=optimal_k)\n",
        "topics = lsa_model.print_topics(num_topics=optimal_k, num_words=10)\n",
        "\n",
        "for topic in topics:\n",
        "    print(topic)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9yVFPGW6i7U"
      },
      "source": [
        "## (3) (10 points) Generate K topics by using  lda2vec, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://nbviewer.org/github/cemoody/lda2vec/blob/master/examples/twenty_newsgroups/lda2vec/lda2vec.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "URPputO_6i7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9627f7eb-9edf-4951-f7f1-e398947e98db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1: 0.056*\"lemmatization\" + 0.056*\"text\" + 0.056*\"punctuation\" + 0.056*\"document\" + 0.056*\"with\" + 0.056*\"sample\" + 0.056*\"tokenized\" + 0.056*\"stopwords\" + 0.056*\"replace\" + 0.056*\"remove\"\n",
            "Topic 2: 0.175*\"your\" + 0.175*\"data\" + 0.175*\"this\" + 0.175*\"replace\" + 0.175*\"with\" + 0.010*\"text\" + 0.010*\"document\" + 0.010*\"lemmatization\" + 0.010*\"stopwords\" + 0.010*\"tokenized\"\n",
            "Topic 3: 0.056*\"lemmatization\" + 0.056*\"text\" + 0.056*\"document\" + 0.056*\"replace\" + 0.056*\"each\" + 0.056*\"data\" + 0.056*\"with\" + 0.056*\"your\" + 0.056*\"sample\" + 0.056*\"required\"\n",
            "Topic 4: 0.056*\"document\" + 0.056*\"with\" + 0.056*\"text\" + 0.056*\"lemmatization\" + 0.056*\"punctuation\" + 0.056*\"your\" + 0.056*\"cleaned\" + 0.056*\"replace\" + 0.056*\"data\" + 0.056*\"stemming\"\n",
            "Topic 5: 0.056*\"replace\" + 0.056*\"document\" + 0.056*\"text\" + 0.056*\"lemmatization\" + 0.056*\"with\" + 0.056*\"tokenized\" + 0.056*\"list\" + 0.056*\"each\" + 0.056*\"cleaned\" + 0.056*\"data\"\n",
            "Topic 6: 0.131*\"your\" + 0.131*\"stemming\" + 0.131*\"data\" + 0.131*\"required\" + 0.131*\"replace\" + 0.131*\"with\" + 0.131*\"lemmatization\" + 0.007*\"document\" + 0.007*\"text\" + 0.007*\"each\"\n",
            "Topic 7: 0.056*\"document\" + 0.056*\"text\" + 0.056*\"lemmatization\" + 0.056*\"each\" + 0.056*\"sample\" + 0.056*\"punctuation\" + 0.056*\"with\" + 0.056*\"required\" + 0.056*\"replace\" + 0.056*\"list\"\n",
            "Topic 8: 0.150*\"remove\" + 0.150*\"cleaned\" + 0.150*\"stopwords\" + 0.150*\"punctuation\" + 0.150*\"text\" + 0.150*\"tokenized\" + 0.008*\"with\" + 0.008*\"each\" + 0.008*\"lemmatization\" + 0.008*\"required\"\n",
            "Topic 9: 0.056*\"text\" + 0.056*\"lemmatization\" + 0.056*\"document\" + 0.056*\"with\" + 0.056*\"sample\" + 0.056*\"punctuation\" + 0.056*\"tokenized\" + 0.056*\"each\" + 0.056*\"data\" + 0.056*\"replace\"\n",
            "Topic 10: 0.056*\"text\" + 0.056*\"document\" + 0.056*\"punctuation\" + 0.056*\"replace\" + 0.056*\"data\" + 0.056*\"with\" + 0.056*\"your\" + 0.056*\"lemmatization\" + 0.056*\"tokenized\" + 0.056*\"required\"\n",
            "Topic 11: 0.056*\"text\" + 0.056*\"document\" + 0.056*\"with\" + 0.056*\"lemmatization\" + 0.056*\"list\" + 0.056*\"sample\" + 0.056*\"each\" + 0.056*\"your\" + 0.056*\"required\" + 0.056*\"replace\"\n",
            "Topic 12: 0.261*\"each\" + 0.261*\"document\" + 0.261*\"list\" + 0.014*\"lemmatization\" + 0.014*\"with\" + 0.014*\"text\" + 0.014*\"tokenized\" + 0.014*\"data\" + 0.014*\"replace\" + 0.014*\"your\"\n",
            "Topic 13: 0.056*\"lemmatization\" + 0.056*\"document\" + 0.056*\"text\" + 0.056*\"with\" + 0.056*\"punctuation\" + 0.056*\"required\" + 0.056*\"list\" + 0.056*\"each\" + 0.056*\"cleaned\" + 0.056*\"tokenized\"\n",
            "Topic 14: 0.056*\"with\" + 0.056*\"document\" + 0.056*\"text\" + 0.056*\"sample\" + 0.056*\"lemmatization\" + 0.056*\"punctuation\" + 0.056*\"tokenized\" + 0.056*\"list\" + 0.056*\"data\" + 0.056*\"replace\"\n",
            "Topic 15: 0.056*\"with\" + 0.056*\"text\" + 0.056*\"lemmatization\" + 0.056*\"document\" + 0.056*\"sample\" + 0.056*\"punctuation\" + 0.056*\"tokenized\" + 0.056*\"each\" + 0.056*\"data\" + 0.056*\"replace\"\n",
            "Topic 16: 0.261*\"text\" + 0.261*\"document\" + 0.261*\"sample\" + 0.014*\"replace\" + 0.014*\"lemmatization\" + 0.014*\"tokenized\" + 0.014*\"each\" + 0.014*\"data\" + 0.014*\"with\" + 0.014*\"required\"\n",
            "Topic 17: 0.056*\"text\" + 0.056*\"lemmatization\" + 0.056*\"document\" + 0.056*\"with\" + 0.056*\"sample\" + 0.056*\"list\" + 0.056*\"punctuation\" + 0.056*\"each\" + 0.056*\"replace\" + 0.056*\"your\"\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import LdaModel\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "# Create a Dictionary and a DTM\n",
        "dictionary = Dictionary(your_corpus)\n",
        "corpus = [dictionary.doc2bow(doc) for doc in your_corpus]\n",
        "\n",
        "# Initialize variables\n",
        "coherence_scores = []\n",
        "k_values = range(2, 21)\n",
        "\n",
        "# Calculate coherence scores for different K values\n",
        "for k in k_values:\n",
        "    lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=k)\n",
        "    coherence_model = CoherenceModel(model=lda_model, texts=your_corpus, dictionary=dictionary, coherence='c_v')\n",
        "    coherence_scores.append(coherence_model.get_coherence())\n",
        "\n",
        "# Find the optimal K with the highest coherence score\n",
        "optimal_k = k_values[coherence_scores.index(max(coherence_scores))]\n",
        "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=optimal_k)\n",
        "topics = lda_model.show_topics(num_topics=optimal_k, num_words=10)\n",
        "\n",
        "for topic in topics:\n",
        "    print(f\"Topic {topic[0] + 1}: {topic[1]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AzfbEvb6i7U"
      },
      "source": [
        "## (4) (10 points) Generate K topics by using BERTopic, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://colab.research.google.com/drive/1FieRA9fLdkQEGDIMYl0I3MCjSUKVF8C-?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMtTg5T_6i7U"
      },
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the BERTopic model\n",
        "model = BERTopic()\n",
        "\n",
        "# Define a range of possible numbers of topics (K)\n",
        "topic_range = range(2, 11)  # Adjust the range as needed\n",
        "\n",
        "best_coherence = -1\n",
        "best_k = None\n",
        "best_topics = None\n",
        "\n",
        "for k in topic_range:\n",
        "    # Fit the model to your data\n",
        "    topics, _ = model.fit(your_corpus)  # Replace your_corpus with your preprocessed text data\n",
        "\n",
        "    # Calculate the coherence score using Gensim's Coherence Model\n",
        "    cm = CoherenceModel(topics=topics, texts=your_corpus, dictionary=dictionary, coherence='c_v')\n",
        "    coherence = cm.get_coherence()\n",
        "\n",
        "    # Check if this K yields a better coherence score\n",
        "    if coherence > best_coherence:\n",
        "        best_coherence = coherence\n",
        "        best_k = k\n",
        "        best_topics = topics\n",
        "\n",
        "print(f\"Best number of topics (K) based on coherence: {best_k}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bertopic\n",
        "from bertopic import BERTopic\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZzXEvv9mefD",
        "outputId": "e214ee55-9fa1-4fc9-c16b-37cc9e8b2005"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bertopic in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.23.5)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.8.33)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.5.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.2.2)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (4.66.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (2.2.2)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (5.15.0)\n",
            "Requirement already satisfied: cython<3,>=0.27 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (0.29.36)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2023.3.post1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (23.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.2.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.35.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.16.0+cu118)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.17.3)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.56.4)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.10)\n",
            "Requirement already satisfied: tbb>=2019.0 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (2021.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.5.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (67.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->bertopic) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.1.7)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT2jSD486i7V"
      },
      "source": [
        "## (5) (10 extra points) Compare the results generated by the four topic modeling algorithms, which one is better? You should explain the reasons in details."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing the results of different topic modeling algorithms (Latent Dirichlet Allocation - LDA, Latent Semantic Analysis - LSA, lda2vec, and BERTopic) can be subjective and context-dependent. The \"better\" algorithm depends on your specific goals and the characteristics of your text data. Here, I'll provide a comparison of these algorithms based on several criteria, and you can make an informed decision based on your specific needs:\n",
        "\n",
        "1. Interpretability:\n",
        "   - LDA and LSA typically generate topics that are easy to interpret because they rely on a bag-of-words approach and provide a list of words associated with each topic.\n",
        "   - lda2vec can offer a balance between interpretability and context by considering word embeddings and document embeddings.\n",
        "   - BERTopic, while powerful, may generate less interpretable topics due to the complexity of BERT embeddings.\n",
        "\n",
        "2. Handling Polysemy:\n",
        "   - LDA, LSA, and lda2vec may struggle with polysemous words (words with multiple meanings) because they rely on simple word counts or vector representations.\n",
        "   - BERTopic, which uses BERT embeddings, can better handle polysemy and capture word context.\n",
        "\n",
        "3. Speed and Scalability:\n",
        "   - LDA, LSA, and lda2vec are often faster and more scalable than BERTopic, especially for large datasets.\n",
        "   - BERTopic can be computationally expensive, but it offers state-of-the-art results when computational resources are available.\n",
        "\n",
        "4. Coherence Score:\n",
        "   - BERTopic can determine the optimal number of topics based on coherence scores, making it easier to select the right number of topics.\n",
        "   - Other algorithms may require manual tuning to determine the number of topics.\n",
        "\n",
        "5. Preprocessing:\n",
        "   - LDA, LSA, and lda2vec often require less preprocessing of text data.\n",
        "   - BERTopic may require substantial text preprocessing and tokenization, which can be more challenging.\n",
        "\n",
        "6. Language and Domain:\n",
        "   - The choice of algorithm may depend on the language and domain of your text data. BERTopic, for example, can perform well across multiple languages, while others may be language-dependent.\n",
        "\n",
        "7. Resources:\n",
        "   - The availability of computational resources, such as CPU, memory, and GPU, may influence your choice. BERTopic can be resource-intensive.\n",
        "\n",
        "8. Task-Specific Goals:\n",
        "   - Consider your specific use case and goals. For document clustering, lda2vec or BERTopic may work well. For topic modeling and interpretability, LDA and LSA are strong choices.\n",
        "\n",
        "Ultimately, the \"better\" algorithm depends on your project's specific requirements. It's advisable to experiment with different algorithms, evaluate their performance using metrics like coherence scores, and consider the interpretability of the results. A combination of different algorithms or ensembling methods can also be a valid approach to harness the strengths of each model."
      ],
      "metadata": {
        "id": "prmKvFstKT9z"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}